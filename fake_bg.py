# Get card with largest similarity
# Plug it back into the input for 0.2 seconds before sending a new trial card
# I guess that means we need something to switch between both modes?
# When the reward dies after multiple successes, switch rules
# Do I need mechanism to make sure that's more gradual the first time a rule change happens?

# I really feel like I need a mechanism to learn from failures, but I can't figure out how. I guess I have to run the model and find out the hard way.